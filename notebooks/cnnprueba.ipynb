{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c24394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True\n",
    "print(torch.cuda.get_device_name(0))  # NVIDIA GeForce RTX 4060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a4f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Transformaciones para entrenamiento (aumentos + normalización)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=0,\n",
    "                            translate=(0.05, 0.05)),  # equivalente a width/height_shift\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Transformaciones para validación y test (solo reescalado + normalización)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cccdb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17739f3e010>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, math, numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# rutas (según tu estructura)\n",
    "# lo que tenías (mal): BASE_DIR = os.path.join(\"002cancer\")\n",
    "BASE_DIR = os.path.join(\"..\", \"002_cancer\")  # desde /notebooks sube a ../002_cancer\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(BASE_DIR, \"val\")\n",
    "TEST_DIR  = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "# parámetros que me pediste\n",
    "CLASSES = 2\n",
    "BATCH   = 32\n",
    "ROWS = COLS = 224\n",
    "INPUT_CH = 3\n",
    "EPOCHS  = 25\n",
    "TEST_MAX_SAMPLES = 2000\n",
    "SEED    = 42\n",
    "\n",
    "# dispositivo\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\",DEVICE)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99777512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: {'Benign': 0, 'Malignant': 1}\n",
      "Train=9504 | Val=2375 | Test=2000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Comprobación de carpetas\n",
    "for p in [TRAIN_DIR, TEST_DIR]:\n",
    "    assert os.path.isdir(os.path.join(p, \"Benign\")),    f\"Falta {p}/Benign\"\n",
    "    assert os.path.isdir(os.path.join(p, \"Malignant\")), f\"Falta {p}/Malignant\"\n",
    "\n",
    "use_explicit_val = os.path.isdir(VAL_DIR) and all(\n",
    "    os.path.isdir(os.path.join(VAL_DIR, c)) for c in [\"Benign\", \"Malignant\"]\n",
    ")\n",
    "\n",
    "if use_explicit_val:\n",
    "    train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
    "    val_ds   = datasets.ImageFolder(VAL_DIR,   transform=val_test_transforms)\n",
    "else:\n",
    "    # Split desde TRAIN -> (train, val)\n",
    "    full_train = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
    "    val_ratio  = 0.2\n",
    "    n_total    = len(full_train)\n",
    "    n_val      = int(n_total * val_ratio)\n",
    "    n_train    = n_total - n_val\n",
    "    train_ds, val_ds = random_split(\n",
    "        full_train, [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(SEED)\n",
    "    )\n",
    "\n",
    "test_ds  = datasets.ImageFolder(TEST_DIR, transform=val_test_transforms)\n",
    "\n",
    "NUM_WORKERS = 0 if os.name == \"nt\" else 4\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(DEVICE.type==\"cuda\"))\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(DEVICE.type==\"cuda\"))\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "# Mapeo de clases\n",
    "if use_explicit_val:\n",
    "    class_to_idx = datasets.ImageFolder(TRAIN_DIR).class_to_idx\n",
    "else:\n",
    "    class_to_idx = train_ds.dataset.class_to_idx if hasattr(train_ds, \"dataset\") else datasets.ImageFolder(TRAIN_DIR).class_to_idx\n",
    "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
    "print(\"Clases:\", class_to_idx)\n",
    "print(f\"Train={len(train_ds)} | Val={len(val_ds)} | Test={len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6f4834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "    (5): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ===== Modelo básico (CNN pequeña) — FIXED =====\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                          # 224 -> 112\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                          # 112 -> 56\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                          # 56 -> 28\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                          # 28 -> 14\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))      # -> (B,256,1,1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                             # -> (B,256)\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(128, num_classes)               # logits\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instancia con tus parámetros globales\n",
    "model = BasicCNN(in_ch=INPUT_CH, num_classes=CLASSES).to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca713d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1cnac\\AppData\\Local\\Temp\\ipykernel_15792\\657509022.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "# Bandera para AMP: True solo si hay GPU\n",
    "USE_AMP = (DEVICE.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_path = \"basic_cnn_best.pt\"\n",
    "patience = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "def run_epoch(loader, train_mode=True):\n",
    "    if train_mode:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    total, correct, running = 0, 0, 0.0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "        if train_mode:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if USE_AMP:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(xb)\n",
    "                loss   = criterion(logits, yb)\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "\n",
    "        if train_mode:\n",
    "            if USE_AMP:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        running += loss.item() * xb.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        total += yb.size(0)\n",
    "        correct += (pred == yb).sum().item()\n",
    "\n",
    "    return running/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c5e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_to_idx: {'Benign': 0, 'Malignant': 1} | malignant_index: 1\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento completo (sin early stopping) guardando histórico\n",
    "import numpy as np, os\n",
    "\n",
    "history = {\n",
    "    \"EPOCHS\": [],\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc\":  [], \"val_acc\":  [],\n",
    "}\n",
    "\n",
    "# Si ya tienes class_to_idx, omite esto.\n",
    "try:\n",
    "    class_to_idx\n",
    "except NameError:\n",
    "    from torchvision import datasets\n",
    "    class_to_idx = datasets.ImageFolder(TRAIN_DIR).class_to_idx\n",
    "\n",
    "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
    "malignant_index = class_to_idx.get(\"Malignant\", 1)  # por si la carpeta se llama distinto, ajusta aquí\n",
    "print(\"class_to_idx:\", class_to_idx, \"| malignant_index:\", malignant_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6e0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_with_fn(loader):\n",
    "    model.eval()\n",
    "    total, correct, running = 0, 0, 0.0\n",
    "    fn_total = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "        if USE_AMP:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(xb)\n",
    "                loss   = criterion(logits, yb)\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "\n",
    "        running += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "\n",
    "        total += yb.size(0)\n",
    "        correct += (preds == yb).sum().item()\n",
    "\n",
    "        # FN = verdaderos Malignant predichos como NO-Malignant\n",
    "        fn_total += ((preds != malignant_index) & (yb == malignant_index)).sum().item()\n",
    "\n",
    "    return running/total, correct/total, fn_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7954ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1cnac\\AppData\\Local\\Temp\\ipykernel_15792\\657509022.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_val_fn   = float(\"inf\")\n",
    "best_path     = \"basic_cnn_minFN.pt\"\n",
    "patience      = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # ---- TRAIN ----\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train_mode=True)\n",
    "\n",
    "    # ---- VAL ----\n",
    "    va_loss, va_acc, va_fn = evaluate_with_fn(val_loader)\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    # >>> guarda en history <<<\n",
    "    history[\"EPOCHS\"].append(epoch)\n",
    "    history[\"train_loss\"].append(tr_loss)\n",
    "    history[\"train_acc\"].append(tr_acc)\n",
    "    history[\"val_loss\"].append(va_loss)\n",
    "    history[\"val_acc\"].append(va_acc)\n",
    "\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}] \"\n",
    "          f\"train_loss={tr_loss:.4f} acc={tr_acc:.3f} | \"\n",
    "          f\"val_loss={va_loss:.4f} acc={va_acc:.3f} | \"\n",
    "          f\"val_FN={va_fn} | \"\n",
    "          f\"LR={optimizer.param_groups[0]['lr']:.6f}\", flush=True)\n",
    "\n",
    "    # ---- guardar mejor por FN; desempate por menor val_loss ----\n",
    "    improved = (va_fn < best_val_fn) or ((va_fn == best_val_fn) and (va_loss < best_val_loss - 1e-4))\n",
    "    if improved:\n",
    "        best_val_fn   = va_fn\n",
    "        best_val_loss = va_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"class_to_idx\": class_to_idx,\n",
    "            \"malignant_index\": malignant_index,\n",
    "            \"best_val_fn\": best_val_fn,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"epoch\": epoch\n",
    "        }, best_path)\n",
    "        print(f\"✔️ Guardado mejor modelo (min FN): FN={best_val_fn}, loss={best_val_loss:.4f} -> {best_path}\", flush=True)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping (sin mejora en FN).\", flush=True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Recargar mejor modelo =====\n",
    "ckpt = torch.load(best_path, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "class_to_idx = ckpt[\"class_to_idx\"]\n",
    "malignant_index = ckpt.get(\"malignant_index\", class_to_idx.get(\"Malignant\", 1))\n",
    "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
    "print(f\"Mejor modelo cargado desde {best_path} | \"\n",
    "      f\"FN={ckpt.get('best_val_fn')} loss={ckpt.get('best_val_loss')}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "epochs  = np.array(history[\"EPOCHS\"], dtype=int)\n",
    "tr_loss = np.array(history[\"train_loss\"], dtype=float)\n",
    "tr_acc  = np.array(history[\"train_acc\"], dtype=float)\n",
    "val_loss= np.array(history[\"val_loss\"], dtype=float)\n",
    "val_acc = np.array(history[\"val_acc\"], dtype=float)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, tr_loss, label=\"Train loss\")\n",
    "plt.plot(epochs, val_loss, label=\"Val loss\")\n",
    "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\"); plt.title(\"Curva de pérdida\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, tr_acc, label=\"Train acc\")\n",
    "plt.plot(epochs, val_acc, label=\"Val acc\")\n",
    "plt.xlabel(\"Época\"); plt.ylabel(\"Exactitud\"); plt.title(\"Curva de exactitud\")\n",
    "plt.legend(); plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7273dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        if USE_AMP:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(xb)\n",
    "        else:\n",
    "            logits = model(xb)\n",
    "        pred = logits.argmax(1).cpu()\n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(yb)\n",
    "\n",
    "all_preds  = torch.cat(all_preds).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "test_acc = (all_preds == all_labels).mean()\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(classification_report(all_labels, all_preds,\n",
    "                            target_names=[idx_to_class[0], idx_to_class[1]]))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=[0,1])\n",
    "\n",
    "plt.figure(figsize=(4.8,4.8))\n",
    "im = plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de confusión\")\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, [idx_to_class[0], idx_to_class[1]], rotation=45, ha=\"right\")\n",
    "plt.yticks(tick_marks, [idx_to_class[0], idx_to_class[1]])\n",
    "plt.xlabel(\"Predicción\"); plt.ylabel(\"Real\")\n",
    "\n",
    "th = cm.max()/2.0 if cm.size > 0 else 0.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > th else \"black\")\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
